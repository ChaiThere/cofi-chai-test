{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thin plate inversion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/tutorials/thin_plate_inversion/thin_plate_inversion.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# What we do in this notebook\n\nWhen modelling the airborne electromagnetic response of subvertical\nbodies such as a volcanogenic massive sulfide deposit they can be\napproximated using a thin plate in the halfspace of a layered earth,\nthat is the 3D response of a thin plate is being considered. Here we use\nCoFI to infer such a thin plate target in the basement of a layered\nearth given airborne electromagnetic data. This tutorial provides a\nguided tour of a subset of the material in\n`` `cofi-examples/examples/vtem_max ``\n\\<https://github.com/inlab-geo/cofi-examples/tree/main/examples/vtem_max\\>\\`\\_\\_.\n\n------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning outcomes\n\n- An understaning of the pitfalls around using a numerical gradient\n- An expos\u00e9 of CoFI's ability to combine a forward solver and a range of\n  inference methods\n- An appreciation of the fact that CoFI only requires limited\n  information about the forward problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Environment setup (uncomment code below)\n# !pip install -U cofi\n# !pip install git+https://github.com/JuergHauser/PyP223.git\n# !pip install smt\n# !git clone https://github.com/inlab-geo/cofi-examples.git\n# %cd cofi-examples/tutorials/thin_plate_inversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# If this notebook is run locally PyP223 and smt need to be installed separately by uncommenting the following lines, \n# that is by removing the # and the white space between it and the exclamation mark.\n# !pip install git+https://github.com/JuergHauser/PyP223.git\n# !pip install smt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem description\n\nGiven airborne electromagnetic data, a common goal in mineral\nexploration is to detect and delineate an economic target, and if this\ntarget is in the form of a subvertical body in the basement, its\nelectromagnetic response can be approximated using at conductive thin\nplate located in the halfspace of a layered earth (e.g.\u00a0Prikhodko et\nal.\u00a02019).\n\nIn this tutorial we look at the inference of such a thin plate with a\nconductance of $2 \\mathrm{S}$ located in a halfspace with a resistivity\nof $1000 \\mathrm{\\Omega m}$ with a $20 \\mathrm{m}$ thick covering layer\nthat has a resistivity of $300 \\mathrm{\\Omega m}$. Specifically we\ndevelop a thin plate inversion method using CoFI to solve the inverse\nproblem and P223 (Raiche et. al., 2007) to solve the forward problem.\n\nSuccessful inversion frequently relies on the objective function being\nsmooth and predictable. For the data being inverted here it is\nadvantageous to convert measurements to scale logarithmically to obtain\na smoother and more predictable objective function when compared with\nusing the unscaled data. Similarly, plate orientation angles are\nconverted into radians and the remaining model parameters are\nlog-scaled.\n\n## Forward solver\n\nThe forward solver is LeroiAir (Raiche et. al, 2007) and the code has\nbeen reorganised so that the response measured by an AEM system here\nVTEMmax is given by a function that can be called from Python. In\nLeroiAir plates are discretised into cells, with the accuracy of the\nforward solver being a function of the chosen cell-size. The forward\nsolver is available in a seperate [Python package\nhere](https://github.com/JuergHauser/PyP223.git).\n\n### Jacobian via finite differencing\n\nParameter estimation methods often rely on the provision of a Jacobian\nfor efficient optimisation. If an analytical Jacobian is not available\none can be computed via finite differencing.\n\n\\$ f'(x_0) = {f(x_0 +h)-f(x_0):raw-latex:\\`over \\`h} \\$\n\nCare must though be taken when choosing the step size $h$, as a too\nsmall step size may result in a Jacobian that is affected by a limited\naccuracy of a forward solver and a too large step size $h$ might result\nin a Jacobian that is not representative of the derivatives at location\n$x_0$. Further to this the gradient of the objective function itself is\naffected by the noise on the data, thus for noisy data choosing a larger\nstep size when computing the Jacobian can be advisable.\n\nIn the following we will be using a relative step size $q$ with $h$\ndefined as $h=x_0*q$.\n\n### VTEMmax AEM system\n\nAirborne electromagnetic systems can be categorised into either\nhelicopter or fixed wing systems. This tutorial is using a VTEMmax\nsystem, a helicopter based system developed and operated by Geotech.\n\n<https://geotech.ca/services/electromagnetic/vtem-versatile-time-domain-electromagnetic-system/>\n\n## Plate parametrisation\n\nThe thin plate is parametrised using the parametrisation introduced in\n(Hauser et. al.\u00a02016). Compared to the commonly employed parametrisation\nwith a plate reference point on the edge of the plate this\nparametrisation allows for a thin plate to grow and shrink around a\nplate refrerence point, without the need to move the reference point.\nThis can be advantageous when there is for example a borehole\nintersecting a thin plate and we seek to determine the extent of the\nthin plate.\n\n## Implementation details\n\nThe problem setup is imported from `forward_lib.py` but can be adjusted\nfor other applications. The wrapper is created so that we can declare\nmodel parameters which are a subset of all the model parameters required\nby the forward problem. This allows to, for example, invert only for dip\nof the thin plate with all the other model parameters assumed to be\nknown.\n\n## Further reading\n\nHauser, J., Gunning, J., & Annetts, D. (2016). Probabilistic inversion\nof airborne electromagnetic data for basement conductors. Geophysics,\n81(5), E389-E400.\n\nPrikhodko, A., Morrison, E., Bagrianski, A., Kuzmin, P., Tishin, P., &\nLegault, J. (2010). Evolution of VTEM? technical solutions for effective\nexploration. ASEG Extended Abstracts, 2010(1), 1-4.\n\nRaiche, A., Sugeng, F. and Wilson, G. (2007) Practical 3D EM inversion\nthe P223F software suite, ASEG Extended Abstracts, 2007:1, 1-5\n\nWheelock, B., Constable, S., & Key, K. (2015). The advantages of\nlogarithmically scaled data for electromagnetic inversion. Geophysical\nJournal International, 201(3), 1765--1780.\n<https://doi.org/10.1093/GJI/GGV107>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# import libraries needed for this example\n\nimport pickle\nimport functools\nimport numpy\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport arviz\nimport cofi\nimport bayesbay\nimport smt\nimport smt.surrogate_models\nimport tqdm\nfrom vtem_max_forward_lib import (\n    problem_setup, \n    system_spec,\n    survey_setup, \n    true_model, \n    ForwardWrapper, \n    plot_transient,\n    plot_predicted_profile,\n    plot_plate_faces, \n    plot_plate_faces_single\n)\n\nnumpy.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem definition\n\nFor convenience we split the problem definition into three objects that\nare initialised with defaults for our synthetic example introduced in\nthe problem description section.\n\n- System specification - `system_spec` - contains information about the\n  AEM system such as the transmitter waveform as well as start and end\n  times of gates.\n- Survey setup - `survey_setup` - contains information about the survey\n  for example the transmitter and receiver locations.\n- Problem setup - `problem_setup` - contains the model and exposes the\n  declared model parameters to CoFI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "survey_setup = {\n    \"tx\": numpy.array([205.]),                  # transmitter easting/x-position\n    \"ty\": numpy.array([100.]),                  # transmitter northing/y-position\n    \"tz\": numpy.array([50.]),                   # transmitter height/z-position\n    \"tazi\": numpy.deg2rad(numpy.array([90.])),  # transmitter azimuth\n    \"tincl\": numpy.deg2rad(numpy.array([6.])),  # transmitter inclination\n    \"rx\": numpy.array([205.]),                  # receiver easting/x-position\n    \"ry\": numpy.array([100.]),                  # receiver northing/y-position\n    \"rz\": numpy.array([50.]),                   # receiver height/z-position\n    \"trdx\": numpy.array([0.]),                  # transmitter receiver separation inline\n    \"trdy\": numpy.array([0.]),                  # transmitter receiver separation crossline\n    \"trdz\": numpy.array([0.]),                  # transmitter receiver separation vertical\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inverting for the dip of a thin plate\n\nWhile a thin plate can not be recovered from a single fiducial, its dip\ncan be recovered from a carefully positioned fiducial. When setting up\nan inverse problem it is good practice to initially setup the simplest\npossible problem and experiment with it to ensure that the forward\nsolver and inference methods work as intended. Before attempting an\ninversion it also is good practice to verify that the misfit function is\nsensitive to the parameter of interest and that the gradient of the\nobjective function points in the right direction.\n\nThe dip of the thin plate thus becomes our declared model parameter and\nwe create the corresponding forward function and set the true value to\n$60\\degree$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forward = ForwardWrapper(true_model, problem_setup, system_spec, survey_setup, [\"pdip\"])\ntrue_param_value = numpy.array([60])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# True model\n\nWe first the plot the true model and the location of the VTEMmax\nmeasurement, which we will be inverting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplt.tight_layout()\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate synthetic data\n\nThis tutorial uses a simplified noise model that assumes an absolute\nnoise, that is a standard deviation of $0.05$ for the logarithms of the\nmeasured and observed data. In the objective and likelihood funtions the\nnoise model is captured in the data covariance matrix, thus a more\nsophisticated noise model, for example, one that accounts for the known\ncorrleation between time gates in AEM data could easily be implemented.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The data \nabsolute_noise= 0.05\n\n# create data and add a realisation of the noise\ndata_pred_true = forward(true_param_value)\ndata_obs = data_pred_true + numpy.random.randn(len(data_pred_true))*absolute_noise\n\n# define data covariance matrix\nsigma=absolute_noise\nCdinv=numpy.identity(len(data_obs))*(1.0/(sigma*sigma))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Starting model\n\nSet an initial guess for the dip of the thin plate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_param_value = numpy.array([45])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define helper functions for CoFI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge: Choose relative step size for the numerical Jacobian\n\nTo compute the numerical Jacobian we need to choose the step size for\nthe perturbation. Here we use a relative step size and if the chosen\nstep size is too large the gradient of the objective function may miss\nthe global minimum, if it is located in a small basins of attraction and\nthus an inversion may never converge. If the step size is chosen too\nsmall the gradient of the objective function will be affected by the\nnoise on the data and the numerical noise of the forward problem. Thus\nthe smallest step size providing a stable gradient is the ideal step\nsize.\n\n*Experiment with relative stape size in the range between :math:\\`0.01\\`\nand :math:\\`0.5\\` and upload the figure of the gradient and misfit\nfunction as a function of plate dip*\n\n[![Upload to\nExcalidraw_1](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=f4481f8278ad2ddcb96d,i9Ki_GouExK4GylmrsrZ2A)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the template below se the relative step size\n\n    my_relative_step = <DEFINE_ME>\n\n    def my_objective(model):\n        dpred = forward(model)\n        residual = dpred - data_obs\n        return residual.T @ Cdinv @ residual\n\n    def my_gradient(model):\n        dpred = forward(model)\n        jacobian = forward.jacobian(model, relative_step = my_relative_step)\n        residual = dpred - data_obs\n        return jacobian.T @ Cdinv @ residual\n\n    def my_hessian(model):\n        jacobian = forward.jacobian(model, relative_step = my_relative_step)\n        return jacobian.T @ Cdinv @ jacobian\n\n    class PerIterationCallbackFunction:\n        def __init__(self):\n            self.x = None\n            self.i = 0\n\n        def __call__(self, xk):\n            print(f\"Iteration #{self.i+1}\")\n            print(f\"  objective value: {my_problem.objective(xk)}\")\n            self.x = xk\n            self.i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <DEFINE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution\n\nmy_relative_step = 0.1\n\ndef my_objective(model):\n    dpred = forward(model)\n    residual = dpred - data_obs\n    return residual.T @ Cdinv @ residual\n\ndef my_gradient(model):\n    dpred = forward(model)\n    jacobian = forward.jacobian(model, relative_step = my_relative_step)\n    residual = dpred - data_obs\n    return jacobian.T @ Cdinv @ residual\n\ndef my_hessian(model):\n    jacobian = forward.jacobian(model, relative_step = my_relative_step)\n    return jacobian.T @ Cdinv @ jacobian\n\nclass PerIterationCallbackFunction:\n    def __init__(self):\n        self.x = None\n        self.i = 0\n\n    def __call__(self, xk):\n        print(f\"Iteration #{self.i+1}\")\n        print(f\"  objective value: {my_problem.objective(xk)}\")\n        self.x = xk\n        self.i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot the misfit and gradient as a function of the plate dip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\nall_models = [numpy.array([pdip]) for pdip in range(40, 120, 5)]\nall_misfits = []\nall_gradients = []\nfor model in all_models:\n    misfit = my_objective(model)\n    gradient = my_gradient(model)\n    all_misfits.append(misfit)\n    all_gradients.append(gradient)\n    print(f\"pdip: {model}, data misfit: {misfit}, gradient: {gradient}\")\n\n\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(all_models, all_misfits,color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xlabel(\"Plate dip\")\nax1.set_ylabel(\"Data misfit\",color=color)\nplt.grid(axis='x')\nax2 = ax1.twinx() \ncolor = 'tab:blue'\nax2.plot(all_models, all_gradients,color=color)\nax2.set_ylabel('Gradient', color=color)\nax2.tick_params(axis='y', labelcolor=color)\nplt.grid(axis='y')\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameter estimation\n\nFirst we solve the inverse problem using optimisation, that is we seek\nto find the minimum of the objective function given as\n\n$$\\chi^2 = (\\mathbf{d} - \\mathbf{f}(\\mathbf{m}))^T\\mathbf{C}_d^{-1}(\\mathbf{d}-\\mathbf{f}(\\mathbf{m})),$$\n\nwhere $\\mathbf{d}$ is the observed data, $\\mathbf{f}(\\mathbf{m})$ the\nmodel prediction and $\\mathbf{C}_d$ the data covariance matrix. The full\nNewton step is then given as\n\n$$\\begin{equation} \\Delta \\mathbf{m}= (\\underbrace{\\mathbf{J}^T \\mathbf{C}_d^{-1} \\mathbf{J}}_{\\mathbf{Hessian}})^{-1}\n(\\underbrace{ \\mathbf{J}^T\\mathbf{C}_d^{-1} \n(\\mathbf{y}-\\mathbf{f}(\\mathbf{m}))}_\\mathbf{Gradient}).\n\\end{equation}$$\n\nThe Jacobian $\\mathbf{J}$ and Hessian, here approximated by\n$\\mathbf{J}^T \\mathbf{C}_d^{-1} \\mathbf{J}$, are only local measures of\nthe first and second derivatives of the objective function and given\nthis a non-linear inverse problem and the numerical derivatives can be\naffected by noise, we can seldom take the full Newton step to compute a\nmodel update as we are likely to overshoot and not improve fit to the\ndata.\n\nOne strategy is to employ a line search to determine the optimal step\nlength, that means the descent direction is given by the full Newton\nstep with the length adjusted so that it does not overshoot and results\nin an improvement of the fit to the data. The major alternative to\nemploying a line search is to use a trust region method. Trust regions\nmethods try to estimate the region around the current model within which\nthe assumption of local linearity holds and then limit the model update\nto stay within that region.\n\n## Further reading\n\n<https://medium.com/intro-to-artificial-intelligence/line-search-and-trust-region-optimisation-strategies-638a4a7490ca>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define CoFI problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_problem = cofi.BaseProblem()\nmy_problem.set_objective(my_objective)\nmy_problem.set_gradient(my_gradient)\nmy_problem.set_hessian(my_hessian)\nmy_problem.set_initial_model(init_param_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define CoFI options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_options = cofi.InversionOptions()\nmy_options.set_tool(\"scipy.optimize.minimize\")\nmy_options.set_params(method=\"Newton-CG\",callback=PerIterationCallbackFunction())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoFI inversion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_inversion = cofi.Inversion(my_problem, my_options)\nmy_result = my_inversion.run()\nprint(f\"\\nNumber of objective function evaluations: {my_result.nfev}\")\nprint(f\"Number of gradient function evaluations: {my_result.njev}\")\nprint(f\"Number of hessian function evaluations: {my_result.nhev}\")\nprint(f\"Solution vector:\\n\",my_result.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data\n\nIn the following we plot the vertical and inline component for the true\nmodel, the starting model and the MAP model that is the maximum a\nposterior model, the solution found by the chosen optimisation method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n_, (ax1, ax2) = plt.subplots(1, 2)\nplot_transient(true_param_value, forward, \"Data from true model\", ax1, ax2, color=\"purple\")\nplot_transient(init_param_value, forward, \"Data from starting model\", ax1, ax2, color=\"green\", linestyle=\":\")\nplot_transient(my_result.model, forward, \"Data from MAP model\", ax1, ax2, color=\"red\", linestyle=\"-.\")\nax1.legend(loc=\"upper center\")\nax2.legend(loc=\"upper center\")\nax1.set_title(\"vertical\")\nax2.set_title(\"inline\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplot_plate_faces(\n    \"plate_init\", forward, init_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"green\", label=\"Starting model\"\n)\nplot_plate_faces(\n    \"plate_inverted\", forward, my_result.model, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"MAP solution\", linestyle=\"dotted\"\n)\nplt.tight_layout()\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble method\n\nParameter estimation methods require an objective function while\nensemble methods require a likelihood function, typically given in the\nform of a log likelihood function. The objective function used for the\nparameter estimation consists of only a data misfit term and thus is\nclosely related to the likelihood function, with the log likelihood\nbeing proportional to the value of the objective function multiplied by\na factor of $-\\frac{1}{2}$\n\n$$p({\\mathbf d} | {\\mathbf m}) \\propto \\exp \\left\\{- \\frac{1}{2} ({\\mathbf d}-{\\mathbf f}({\\mathbf m}))^T C_d^{-1} ({\\mathbf d}-{\\mathbf f}({\\mathbf m})) \\right\\}$$\n\nTo use an ensemble method in CoFI we will need to define a likelihood\nfunction and prior distribution. The prior distribution we choose here\nis a uniform distribution with a lower boundary of $10 \\degree$ and an\nupper boundary of $80 \\degree$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m_min=numpy.array([10])\nm_max=numpy.array([80])\n\ndef my_log_prior(m):    # uniform distribution\n    for i in range(len(m)):\n        if m[i] < m_min[i] or m[i] > m_max[i]: return -numpy.inf\n    return 0.0 # model lies within bounds -> return log(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge: Given the objective function define a log likelihood function.\n\nIn the previous section we defined the following objective function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_objective(model):\n    dpred = forward(model)\n    residual = dpred - data_obs\n    return residual.T @ Cdinv @ residual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function can be used to now create the log likelihood function,\ntypically needed by the ensemble methods made available in CoFI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_log_likelihood(model):\n    return # DEFINE ME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution\ndef my_log_likelihood(model):\n    return -0.5 * my_objective(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Augment the CoFI problem\n\nTo finally be able to use an ensemble method we also need to augment our\nCoFI problem with the functions we defined for the log of the prior\nprobability and the log of the likelihood function. We will again be\nusing `emcee`, which we already used in the linear regression tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_problem.set_log_prior(my_log_prior)\nmy_problem.set_log_likelihood(my_log_likelihood)\nmy_problem.set_model_shape(len(init_param_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define CoFI options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nwalkers = 2\nndim = len(init_param_value)\nnsteps = 50\nwalkers_start = init_param_value + 1 * numpy.random.randn(nwalkers, ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoFI Inversion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options = cofi.InversionOptions()\ninv_options.set_tool(\"emcee\")\ninv_options.set_params(nwalkers=nwalkers, nsteps=nsteps, initial_state=walkers_start, progress=True)\n\n######## Run it\ninv = cofi.Inversion(my_problem, inv_options)\nmy_result = inv.run()\n\n######## Check result\nprint(f\"The inversion result from `emcee`:\")\nmy_result.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\nsampler = my_result.sampler\narviz.style.use(\"default\")\nvar_names = [\n    \"plate dip (\\u00b0)\", \n]\naz_idata = my_result.to_arviz(var_names=var_names)\narviz.plot_trace(az_idata.sel(draw=slice(0,None)),lines=(('plate dip (\\u00b0)', {}, 60),));\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While both chains have moved away from the starting model in the\ndirection of the true dip the 50 samples are not enough to recover the\nposterior distribution. In practice a longer chain would be needed, but\nthis would increase the number of times we need to call the forward\nproblem which is computationally expensive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Limited computational resources\n\nFrom our tests we know that the objective function appears smooth and\nwell behaved with a large basin of attraction, thus we can create a\nsurrogate model. The basic idea is that given samples of the objective\nfunction as a function of the declared model parameters we can\ninterpolate a response surface and use it instead of solving the\ncomputationally more expensive forward problem when we need to evaluate\nthe log likelihood function. Evaluating the surrogate model will take a\nfraction of the time. In the following we thus create a surrogate model\nfor the objective function using [the surrogate modelling\ntoolbox](https://smt.readthedocs.io/en/latest/).\n\nWe first generate random samples of the objective function using [latin\nhypercube\nsampling](https://en.wikipedia.org/wiki/Latin_hypercube_sampling).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title random samples of the objective function in the range 10 to 90 for the dip.\nndim=len(true_param_value)\nxlimits=numpy.array([[10,90]])\nntrain=25\nntest=5\nsampling = smt.sampling_methods.LHS(xlimits=xlimits,random_state=42)\nxtrain=sampling(ntrain)\nytrain=[]\nxtest=sampling(ntest)\nytest=[]\nfor x in tqdm.tqdm(xtrain):\n    ytrain.append(my_objective(x))\nfor x in tqdm.tqdm(xtest):\n    ytest.append(my_objective(x))\nytrain=numpy.array(ytrain)\nytest=numpy.array(ytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we create the surrogate model itself, that is here the construction\nof a response surface using Kriging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sm = smt.surrogate_models.KRG(theta0=[1e-2]*ndim,print_prediction = False)\nsm.set_training_values(xtrain,ytrain)\nsm.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we test how well our surrogate model predicts the value of the\nobjective function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title prediction of the validation points\ny = sm.predict_values(xtest)\n# Estimated variance for the validation points\ns2 = sm.predict_variances(xtest)\n#plot with the associated interval confidence\nyerr= 2*3*numpy.sqrt(s2) #in order to use +/- 3 x standard deviation: 99% confidence interval estimation\n\n# Plot the function, the prediction and the 99% confidence interval based on\n# the MSE\nfig = plt.figure()\nplt.plot(ytest, ytest, '-', label='$y_{true}$')\nplt.plot(ytest, y, 'r.', label='$\\\\hat{y}$')\nplt.errorbar(numpy.squeeze(ytest), numpy.squeeze(y), yerr=numpy.squeeze(yerr), fmt = 'none', capsize = 5, ecolor = 'lightgray', elinewidth = 1, capthick = 0.5, label='confidence estimate 99%')\nplt.xlabel('$y_{true}$')\nplt.ylabel('$\\\\hat{y}$')\n\nplt.legend(loc='upper left')\nplt.title('Validation of the model prediction with confidence estimates')   \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we run `emcee` again, but we call the surrogate model instead of the\nP223 kernel and thus we can generate more samples of the posterior\ndistribution in a fraction of the time. It is however important to keep\nin mind that the surrogate model is only an approximation and likely to\nhave a limited accuracy particularly if we increase the number of\ndeclared model parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nwalkers = 5\nndim = len(init_param_value)\nnsteps = 500\nwalkers_start = init_param_value + 1 * numpy.random.randn(nwalkers, ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_objective(model):\n    val=sm.predict_values(numpy.array([model]))[0][0]\n    if val<1e-3:\n        return 1e-3\n    else:\n        return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options = cofi.InversionOptions()\ninv_options.set_tool(\"emcee\")\ninv_options.set_params(nwalkers=nwalkers, nsteps=nsteps, initial_state=walkers_start, progress=True)\n\n######## Run it\ninv = cofi.Inversion(my_problem, inv_options)\nmy_result = inv.run()\n\n######## Check result\nprint(f\"The inversion result from `emcee`:\")\nmy_result.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\nsampler = my_result.sampler\narviz.style.use(\"default\")\nvar_names = [\n    \"plate dip (\\u00b0)\", \n]\naz_idata = my_result.to_arviz(var_names=var_names)\narviz.plot_trace(az_idata.sel(draw=slice(100,None)),lines=(('plate dip (\\u00b0)', {}, 60),));\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inverting for a thin plate given three survey lines\n\nA more realistic synthetic example is the inference of a thin plate\ntarget given three survey lines. It now becomes possible to invert for\nthe easting, depth of the plate reference point, the plate dip and plate\nazimuth and the plate length.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem setup\n\nIn the following we define three survey lines covering the thin plate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tx_min = 115\ntx_max = 281\ntx_interval = 15\nty_min = 25\nty_max = 176\nty_interval = 75\ntx_points = numpy.arange(tx_min, tx_max, tx_interval)\nty_points = numpy.arange(ty_min, ty_max, ty_interval)\nn_transmitters = len(tx_points) * len(ty_points)\ntx, ty = numpy.meshgrid(tx_points, ty_points)\ntx = tx.flatten()\nty = ty.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fiducial_id = numpy.arange(len(tx))\nline_id = numpy.zeros(len(tx), dtype=int)\nline_id[ty==ty_points[0]] = 0\nline_id[ty==ty_points[1]] = 1\nline_id[ty==ty_points[2]] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "survey_setup = {\n    \"tx\": tx,                                                   # transmitter easting/x-position\n    \"ty\": ty,                                                   # transmitter northing/y-position\n    \"tz\": numpy.array([50]*n_transmitters),                     # transmitter height/z-position\n    \"tazi\": numpy.deg2rad(numpy.array([90]*n_transmitters)),    # transmitter azimuth\n    \"tincl\": numpy.deg2rad(numpy.array([6]*n_transmitters)),    # transmitter inclination\n    \"rx\": tx,                                                   # receiver easting/x-position\n    \"ry\": numpy.array([100]*n_transmitters),                    # receiver northing/y-position\n    \"rz\": numpy.array([50]*n_transmitters),                     # receiver height/z-position\n    \"trdx\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation inline\n    \"trdy\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation crossline\n    \"trdz\": numpy.array([0]*n_transmitters),                    # transmitter receiver separation vertical\n    \"fiducial_id\": fiducial_id,                                 # unique id for each transmitter\n    \"line_id\": line_id                                          # id for each line\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# True model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "true_model = {\n    \"res\": numpy.array([300, 1000]), \n    \"thk\": numpy.array([20]), \n    \"peast\": numpy.array([175]), \n    \"pnorth\": numpy.array([100]), \n    \"ptop\": numpy.array([30]), \n    \"pres\": numpy.array([0.1]), \n    \"plngth1\": numpy.array([100]), \n    \"plngth2\": numpy.array([100]), \n    \"pwdth1\": numpy.array([0.1]), \n    \"pwdth2\": numpy.array([90]), \n    \"pdzm\": numpy.array([75]),\n    \"pdip\": numpy.array([60])\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now increase the number of declared model parameters and they include\nthe plate dip, the plate dip azimuth, the easting of the plate reference\npoint, the depth of the plate reference point and the plate width and\nwill only be using the vertical component.\n\nAs a general rule we can only constrain parameters if there are\nfiducials in the survey that are sensitive to them and also fiducials\nthat are not sensitive to them. In order words the anomaly needs to be\nclosed with respect to the model parameter in question; to for example\nconstrain plate length we would need survey lines to the north and south\nthat are not overflying the thin plate, as this is not the case in our\nsetup we do not invert for plate length.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forward = ForwardWrapper(true_model, problem_setup, system_spec, survey_setup,\n                         [\"pdip\",\"pdzm\", \"peast\", \"pwdth2\",\"ptop\"], data_returned=[\"vertical\"]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# check the order of parameters in a model vector\nforward.params_to_invert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "true_param_value = numpy.array([60,65, 175, 30, 90])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplt.tight_layout()\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate synthetic data\n\nWe again generate a synthetic data set and add a realisation of the\nnoise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The data \nabsolute_noise= 0.05\n\n# create data and add a realisation of the noise\ndata_pred_true = forward(true_param_value)\ndata_obs = data_pred_true + numpy.random.randn(len(data_pred_true))*absolute_noise\n\n# define data covariance matrix\nsigma=absolute_noise\nCdinv=numpy.identity(len(data_obs))*(1.0/(sigma*sigma))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge: Implement a parameter estimation or ensemble method in CoFI\n\nCoFI is about experimentation and given the experiments in the previous\nsection you can now head down a branch of the CoFI tree and infer a thin\nplate from the synthetic data we just generated. The first choice is\nbetween parameter estimation and ensemble methods.\n\n- [Parameter\n  estimation](#Parameter-estimation-applied-to-three-survey-lines)\n- [Ensemble methods](#Ensemble-methods-applied-to-three-survey-lines)\n\n::: {.container .alert .alert-block .alert-info}\nColab: If this notebook is used on colab anchor links will currently not\nwork and the table of contents needs to be used to navigate to the\nrelevant section... #3983\n:::\n\nThe parameter estimation methods call the forward kernel and compute a\nnumerical Jacobian, while the ensemble methods will in the following\nagain use a surrogate model to compute the objective/likelihood\nfunction, which takes a fraction of a second. **Thus the suggestion is\nto use an ensemble method.**\n\n*Once you have performed an inversion using CoFI upload your solution*\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameter estimation applied to three survey lines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Initialise a model for inversion**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forward.params_to_invert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_param_value = numpy.array([45, 90, 150, 20, 80])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define helper functions for CoFI**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_objective(model):\n    dpred = forward(model)\n    residual = dpred - data_obs\n    return residual.T @ Cdinv @ residual\n\ndef my_gradient(model):\n    dpred = forward(model)\n    jacobian = forward.jacobian(model, relative_step=0.1)\n    residual = dpred - data_obs\n    return jacobian.T @ Cdinv @ residual\n\ndef my_hessian(model):\n    jacobian = forward.jacobian(model)\n    return jacobian.T @ Cdinv @ jacobian\n\nclass PerIterationCallbackFunction:\n    def __init__(self):\n        self.x = None\n        self.i = 0\n\n    def __call__(self, xk):\n        print(f\"Iteration #{self.i+1}\")\n        print(f\"  objective value: {my_problem.objective(xk)}\")\n        self.x = xk\n        self.i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define CoFI problem**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_problem = cofi.BaseProblem()\nmy_problem.set_objective(my_objective)\nmy_problem.set_gradient(my_gradient)\nmy_problem.set_hessian(my_hessian)\nmy_problem.set_initial_model(init_param_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge: Choose a parameter estimation method\n\nCoFI provides access to the parameter estimation methods that are\navailable in `` `scipy.optimize.minimize ``\n\\<https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\\>\\`\\_\\_\n\nFor practical application we are interested in a solver that converges\nwith the fewest calls to the forward problem to a model that is\nacceptably close to the true model and explains the data. The\nconsequence of employing a line search or trust region method or more\nbroadly any method seeking to find the optimal step length is, that\ntypically additional calls to a forward problem need to be made to\ndetermine the optimal step length and different approaches require\ndifferent numbers of calls to the forward problem depending on the shape\nof the objective function.\n\n::: {.container .alert .alert-block .alert-info}\nColab: The computational resources offered by colab for free are limited\nand thus the inverisons performed in the following may take a while if\nthe free resources offered by colab are being used...\n:::\n\n*Choose one of the following two solvers and perform a parameter\nestimation using CoFI and upload your solution* - `newton-cg`\n-<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-newtoncg.html> -\n`trust-ncg`-<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-trustncg.html>\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define CoFI options**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the template below and set the CoFI tool to `newton-cg` or\n`trust-ncg`\n\n    my_options = cofi.InversionOptions()\n    my_options.set_tool(\"scipy.optimize.minimize\")\n    my_options.set_params(method=<DEFINE_ME>,callback=PerIterationCallbackFunction(),options={\"maxiter\": 10})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <DEFINE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution newton-cg\nmy_options = cofi.InversionOptions()\nmy_options.set_tool(\"scipy.optimize.minimize\")\nmy_options.set_params(method=\"newton-cg\",callback=PerIterationCallbackFunction(),options={\"maxiter\": 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution trust-ncg\nmy_options = cofi.InversionOptions()\nmy_options.set_tool(\"scipy.optimize.minimize\")\nmy_options.set_params(method=\"trust-ncg\",callback=PerIterationCallbackFunction(),options={\"maxiter\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run CoFI inversion**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_inversion = cofi.Inversion(my_problem, my_options)\nmy_result = my_inversion.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data - Profiles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\n# Select gates to plot\nidx_to_plot = numpy.arange(8, 30) \n\n_, axes = plt.subplots(3, 1, figsize=(12,12))\n\nfor i in range(3):\n    plot_predicted_profile(true_param_value, forward, \"Data from true model\", gate_idx=idx_to_plot, \n                                        line_id=[i], ax=axes[i], color=\"purple\")\n    plot_predicted_profile(init_param_value, forward, \"Data from starting model\", gate_idx=idx_to_plot, \n                                        line_id=[i], ax=axes[i], color=\"green\", linestyle=\":\")\n    plot_predicted_profile(my_result.model, forward, \"Data from MAP model\", gate_idx=idx_to_plot, \n                                        line_id=[i], ax=axes[i], color=\"red\", linestyle=\"-.\")\n    axes[i].set_title(\"Crossline {} (m)\".format(ty_points[i]))\n    axes[i].legend(bbox_to_anchor=(1.04, 0), loc=\"lower left\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplot_plate_faces(\n    \"plate_init\", forward, init_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"green\", label=\"Starting model\"\n)\nplot_plate_faces(\n    \"plate_inverted\", forward, my_result.model, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"MAP model\", linestyle=\"dotted\"\n)\n\nplt.tight_layout()\n\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble methods applied to three survey lines\n\nTo speed up the forward computations for this tutorial and to be able to\nuse ensemble methods we again create a surrogate model for the objective\nfunction using [the surrogate modelling\ntoolbox](https://smt.readthedocs.io/en/latest/).\n\nThe two steps to create the surrogate model are the sampling of the\nobjective function using latin hypercube sampling and the creation of\nthe surrogate model itself, that is here the construction of a response\nsurface using Kriging. For completness the two notebooks implementing\nthis are given here: - [Latin Hypercube\nSampling](https://github.com/inlab-geo/cofi-examples/blob/main/examples/vtem_max/three_survey_lines_latin_hypercube_sampling.ipynb) -\n[Surrogate model\ncreation](https://github.com/inlab-geo/cofi-examples/blob/main/examples/vtem_max/three_survey_lines_surrogate_model_creation.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Create surrogate model given latin hypercube samples\n\n# Different versions of the surrogate modelling toolbox store the model in different\n# formats thus it is safer to just create the model on the fly given the latin hypercube\n# samples which here are pre-computed.\n\nwith open('three_survey_lines_lhs.npy', 'rb') as f:\n    ndim=int(numpy.load(f))\n    xlimits=numpy.load(f) \n    xtrain=numpy.load(f)\n    ytrain=numpy.load(f)\n    xtest=numpy.load(f)\n    ytest=numpy.load(f)\n\nxlimits=xlimits.astype('double')\nxtrain=xtrain[0:100].astype('double')\nytrain=ytrain[0:100].astype('double')\nxtest=xtest[0:10].astype('double')\nytest=ytest[0:10].astype('double')\n\nsm = smt.surrogate_models.KRG(theta0=[1e-2]*ndim,print_prediction = False)\nsm.set_training_values(xtrain,ytrain)\nsm.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Initialise a model for inversion and define prior distribution**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_param_value = numpy.array([45, 90, 160, 35, 80])\nm_min = numpy.array([15, 35, 155, 30, 65])\nm_max = numpy.array([75, 145, 185, 40, 115])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define helper functions for CoFI**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_objective(model):\n    val=sm.predict_values(numpy.array([model]))[0][0]\n    if val<1e-3:\n        return 1e-3\n    else:\n        return val\n        \ndef my_log_likelihood(model):\n    return -0.5 * my_objective(model)\n\n\ndef my_log_prior(model):    # uniform distribution\n    for i in range(len(model)):\n        if model[i] < m_min[i] or model[i] > m_max[i]: return -numpy.inf\n    return 0.0 # model lies within bounds -> return log(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge: Select an ensemble method\n\nThe nature of the airborne electromagnetic forward physics is that the\ndeeper a feature of interest the less well it can be recovered. This\ninformation is not captured in the solution obtained using a parameter\nestimation method. CoFI provides access to range of ensemble methods\nthat recover the distribution of models that fit the data and thus\nallows to estimate model uncertainty.\n\n*Using one of the following three ensemble methods available in CofI\ncomplete the relevant section and upload your solution.*\n\n- `` `emcee `` Affine Invariant Markov chain Monte Carlo Ensemble\n  sampler\n  \\<#Affine-Invariant-Markov-chain-Monte-Carlo-Ensemble-sampler\\>\\`\\_\\_\n- `` `neighpy `` Neighbourhood algorithm\n  \\<#Neighbourhood-algorithm\\>\\`\\_\\_\n- `` `bayesbay `` Metropolis Hastings algorithm\n  \\<#Metropolis-Hastings-algorithm\\>\\`\\_\\_\n\n::: {.container .alert .alert-block .alert-info}\nColab: If this notebook is used on colab anchor links will currently not\nwork and the table of contents needs to be used to navigate to the\nrelevant section... #3983\n:::\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Affine Invariant Markov chain Monte Carlo Ensemble sampler\n\nUsing `emcee` as the string in `inv_options.set_tool()` CoFI offers an\ninterface to the Affine Invariant Markov chain Monte Carlo (MCMC)\nEnsemble sampler by [Goodman and Weare\n2010](https://msp.org/camcos/2010/5-1/p04.xhtml) to sample the posterior\ndistribution. (See more details about\n[emcee](https://emcee.readthedocs.io/en/stable/)).\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_problem = cofi.BaseProblem()\nmy_problem.set_log_prior(my_log_prior)\nmy_problem.set_log_likelihood(my_log_likelihood)\nmy_problem.set_model_shape(len(init_param_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define CoFI options**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title defaults for emcee\nnwalkers = 12\nndim = len(init_param_value)\nnsteps = 5000\nwalkers_start = init_param_value + 0.5 * numpy.random.randn(nwalkers, ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the template below and set the CoFI tool to `emcee`\n\n    inv_options = cofi.InversionOptions()\n    inv_options.set_tool(<DEFINE_ME>)\n    inv_options.set_params(nwalkers=nwalkers, nsteps=nsteps, initial_state=walkers_start, progress=True)\n\n    ######## Run it\n    inv = cofi.Inversion(my_problem, inv_options)\n    my_result = inv.run()\n\n    ######## Check result\n    print(f\"The inversion result from `emcee`:\")\n    my_result.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <DEFINE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution\n\ninv_options = cofi.InversionOptions()\ninv_options.set_tool(\"emcee\")\ninv_options.set_params(nwalkers=nwalkers, nsteps=nsteps, initial_state=walkers_start, progress=True)\n\n######## Run it\ninv = cofi.Inversion(my_problem, inv_options)\nmy_result = inv.run()\n\n######## Check result\nprint(f\"The inversion result from `emcee`:\")\nmy_result.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\n\nvar_names = [\n    \"Dip (\\u00b0)\",\n    \"Dip azimuth (\\u00b0)\",\n    \"Easting (m)\",\n    \"Depth (m)\",\n    \"Width (m)\",\n]\n\nvar_lines=(\n        ('Dip (\\u00b0)', {}, 60),\n        ('Dip azimuth (\\u00b0)', {}, 65),\n        ('Easting (m)', {}, 175),\n        ('Depth (m)', {}, 30),\n        ('Width (m)', {}, 90)\n)\nsampler = my_result.sampler\naz_idata = my_result.to_arviz(var_names=var_names)\narviz.plot_trace(az_idata.sel(draw=slice(2000,None)),lines=var_lines);\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\ntrue_values = {\n    f\"{var_names[i]}\": true_param_value[i] for i in range(init_param_value.size)\n}\nfig, axes = plt.subplots(5, 5, figsize=(10, 8))\n_ = arviz.plot_pair(\naz_idata.sel(draw=slice(4000,None)), \n    marginals=True,\n    kind=\"kde\",\n    kde_kwargs={\n        \"hdi_probs\": [0.3, 0.6, 0.9],  # Plot 30%, 60% and 90% HDI contours\n        \"contourf_kwargs\": {\"cmap\": \"Blues\"},\n    },\n    ax=axes,\n    textsize=10,\n)\n\nfor i, j in numpy.ndindex(axes.shape):\n    if i == j:\n        continue\n    xlabel = axes[-1, j].get_xlabel()\n    ylabel = axes[i, 0].get_ylabel()\n    x_true = true_values[xlabel]\n    y_true = true_values[ylabel]        \n    axes[i, j].plot(x_true, y_true, \"yellow\", marker=\"o\", ms=10, markeredgecolor=\"k\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\n\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplot_plate_faces(\n    \"plate_init\", forward, init_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"green\", label=\"Starting model\"\n)\n\n\nplt.tight_layout()\n\n\nichain=0\nidraw=2500\nsample=numpy.zeros(5)\n\nsample[0]=az_idata.posterior['Dip (\\u00b0)'][ichain][idraw]\nsample[1]=az_idata.posterior['Dip azimuth (\\u00b0)'][ichain][idraw]\nsample[2]=az_idata.posterior['Easting (m)'][ichain][idraw]\nsample[3]=az_idata.posterior['Depth (m)'][ichain][idraw]\nsample[4]=az_idata.posterior['Width (m)'][ichain][idraw]\nplot_plate_faces(\n    \"plate_inverted\", forward, sample, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"Posterior sample\", linestyle=\"dotted\"\n)\n\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")\n\n\n# plot 10 randomly selected samples of the posterior distirbution\nfor i in range(10):\n    ichain=numpy.random.randint(0,12)\n    idraw=numpy.random.randint(2000,5000)\n    sample[0]=az_idata.posterior['Dip (\\u00b0)'][ichain][idraw]\n    sample[1]=az_idata.posterior['Dip azimuth (\\u00b0)'][ichain][idraw]\n    sample[2]=az_idata.posterior['Easting (m)'][ichain][idraw]\n    sample[3]=az_idata.posterior['Depth (m)'][ichain][idraw]\n    sample[4]=az_idata.posterior['Width (m)'][ichain][idraw]\n    plot_plate_faces(\n    \"plate_inverted\", forward, sample, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"Posterior sample\", linestyle=\"dotted\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neighbourhood algorithm\n\nThe [Neighbourhood\nAlgorithm](https://iearth.edu.au/codes/NA/#:~:text=Overview-,The%20neighbourhood%20algorithm%20is%20a%20two%2Dstage%20numerical%20procedure%20for,in%20a%20multidimensional%20parameter%20space.)\nis a two-stage ensemble method for non-linear inverse problems with\napplication as a direct search method for global optimisation. The first\nstage seeks to find points in model space with acceptable values of the\nobjective function. The second stage analysis the ensemble of models\ngenerated in the first stage and provides Bayesian measures of\nproperties of the ensemble such as resolution and covariance structure.\n\nHere CoFI is providing an interface the the implementation of the\nNeighbourhood Algorithm provided by\n[neighpy](https://neighpy.readthedocs.io/en/latest/) and it is accessed\nby using `neighpy` as the string in `inv_options.set_tool()`\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_problem = cofi.BaseProblem()\nmy_problem.set_objective(my_objective)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the template below set the CoFI tool to `neighpy`\n\n    inv_options = cofi.InversionOptions()\n    inv_options.set_tool(<DEFINE_ME>)\n    inv_options.suggest_solver_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <DEFINE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution\ninv_options = cofi.InversionOptions()\ninv_options.set_tool(\"neighpy\")\ninv_options.suggest_solver_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options.set_params(\n    n_samples_per_iteration=100,\n    n_initial_samples=10,\n    n_resample=8000,\n    n_iterations=100,\n    bounds=numpy.array([m_min, m_max]).T,\n    n_cells_to_resample=10,\n    n_walkers=4\n)\n\n######## Run it\ninv = cofi.Inversion(my_problem, inv_options)\nmy_result = inv.run()\n\n######## Check result\nprint(f\"The inversion result from `neighpy`:\")\nmy_result.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\nvar_names = [\n    \"Dip (\\u00b0)\", \n    \"Dip azimuth (\\u00b0)\", \n    \"Easting (m)\", \n    \"Depth (m)\", \n    \"Width (m)\"\n]\n\nvar_lines=(\n    ('Dip (\\u00b0)', {}, 60),\n        ('Dip azimuth (\\u00b0)', {}, 65),\n        ('Easting (m)', {}, 175),\n        ('Depth (m)', {}, 30),\n        ('Width (m)', {}, 90)\n)\nd = {k: v for k, v in zip(var_names, my_result.appraisal_samples.T)}\naz_idata = arviz.convert_to_inference_data(d)\narviz.plot_trace(az_idata.sel(draw=slice(2000,None)),lines=var_lines)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\n\n_, axes = plt.subplots(5, 5, figsize=(12,12))\narviz.plot_pair(\n    az_idata.sel(draw=slice(4000,None)), \n    marginals=True, \n    ax = axes\n)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\n\n_, axes = plt.subplots(2, 2)\naxes[1,1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\", forward, true_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"purple\", label=\"True model\"\n)\nplot_plate_faces(\n    \"plate_init\", forward, init_param_value, \n    axes[0,0], axes[0,1], axes[1,0], color=\"green\", label=\"Starting model\"\n)\n\n\nplt.tight_layout()\n\n\nichain=0\nidraw=2500\nsample=numpy.zeros(5)\n\nsample[0]=az_idata.posterior['Dip (\\u00b0)'][ichain][idraw]\nsample[1]=az_idata.posterior['Dip azimuth (\\u00b0)'][ichain][idraw]\nsample[2]=az_idata.posterior['Easting (m)'][ichain][idraw]\nsample[3]=az_idata.posterior['Depth (m)'][ichain][idraw]\nsample[4]=az_idata.posterior['Width (m)'][ichain][idraw]\nplot_plate_faces(\n    \"plate_inverted\", forward, sample, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"Posterior sample\", linestyle=\"dotted\"\n)\n\npoint = Line2D([0], [0], label='Fiducial', marker='o', markersize=5, \n         markeredgecolor='orange', markerfacecolor='orange', linestyle='')\n\nhandles, labels = axes[1,0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1,0].legend(handles=handles,bbox_to_anchor=(1.04, 0), loc=\"lower left\")\n\n\n# plot 10 randomly selected samples of the posterior distirbution\nfor i in range(10):\n    idraw=numpy.random.randint(2000,5000)\n    sample[0]=az_idata.posterior['Dip (\\u00b0)'][ichain][idraw]\n    sample[1]=az_idata.posterior['Dip azimuth (\\u00b0)'][ichain][idraw]\n    sample[2]=az_idata.posterior['Easting (m)'][ichain][idraw]\n    sample[3]=az_idata.posterior['Depth (m)'][ichain][idraw]\n    sample[4]=az_idata.posterior['Width (m)'][ichain][idraw]\n    plot_plate_faces(\n    \"plate_inverted\", forward, sample, \n    axes[0,0], axes[0,1], axes[1,0], color=\"red\", label=\"Posterior sample\", linestyle=\"dotted\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metropolis Hastings algorithm\n\nTo sample the posterior distribution,\n[BayesBay](https://github.com/fmagrini/bayes-bay) implements an RJ-MCMC\nmethod, which is a generalization of the Metropolis-Hastings algorithm\nallowing for trans-dimensional inference. Here we use\n[BayesBay](https://github.com/fmagrini/bayes-bay) to solve a fixed\ndimensional problem as the number of thin plate targets is one. BayesBay\nis accessed from CoFI by using `bayesbay` as the string in\n`inv_options.set_tool()`\n\n[![Upload to\nExcalidraw_2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Excalidraw-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://excalidraw.com/#room=52f0ac5f10e0111ee085,3nYggMVJOpmqlV1ZbYj0Eg)\n\nAn example for CoFI using\n[BayesBay](https://github.com/fmagrini/bayes-bay) to solve a\ntrans-dimensional inverse problem is given\n[here](https://github.com/inlab-geo/cofi-examples/blob/main/examples/partition_modelling/Partition_modelling_sealevel_bayesbay.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title defaults for bayesbay\n\ndef initialize_param(param, position=None, value=1):\n    return numpy.array([value]) + 0.5 * numpy.random.randn()\n\nparameters = []\nfor iparam, (vmin, vmax) in enumerate(zip(m_min, m_max)):\n    parameter = bayesbay.prior.UniformPrior(\n        name=f\"m{iparam}\",\n        vmin=m_min[iparam],\n        vmax=m_max[iparam],\n        perturb_std=(vmax - vmin) / 20,\n    )\n    custom_init = functools.partial(initialize_param, value=init_param_value[iparam])\n    parameter.set_custom_initialize(custom_init)\n    parameters.append(parameter)\n\nparam_space = bayesbay.parameterization.ParameterSpace(\n    name=\"param_space\",\n    n_dimensions=1,\n    parameters=parameters,\n)\nparameterization = bayesbay.parameterization.Parameterization(param_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title wrap log likelihood function for bayesbay\ndef my_log_likelihood(state, *args, **kwargs):\n    model = numpy.array(\n        [state[\"param_space\"][f\"m{i}\"] for i in range(init_param_value.size)]\n    )\n    return -0.5 * my_objective(model.T[0])\n\nlog_likelihood = bayesbay.likelihood.LogLikelihood(log_like_func=my_log_likelihood) # BayesBay version 3.1 and above\n#log_likelihood = bayesbay.LogLikelihood(log_like_func=my_log_likelihood)  # BayesBay pre version 3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title bayesbay initialisation\nn_chains = 12\nwalkers_start = []\nfor i in range(n_chains):\n    walkers_start.append(\n        parameterization.initialize()\n    )  # A bayesbay.State is appended to walkers_start for each chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the template below set the CoFI tool to `bayesbay`\n\n    inv_options = cofi.InversionOptions()\n    inv_options.set_tool(<DEFINE ME>)\n    inv_options.set_params(\n        walkers_starting_states=walkers_start,\n        perturbation_funcs=parameterization.perturbation_funcs,  # BayesBay version 3.1 and above\n        #perturbation_funcs=parameterization.perturbation_functions, # BayesBay pre version 3.1 \n        log_like_ratio_func=log_likelihood,\n        n_chains=n_chains,\n        n_iterations=5_000,\n        burnin_iterations=500,\n        verbose=False,\n        save_every=25,\n    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <DEFINE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution\ninv_options = cofi.InversionOptions()\ninv_options.set_tool(\"bayesbay\")\ninv_options.set_params(\n    walkers_starting_states=walkers_start,\n    perturbation_funcs=parameterization.perturbation_funcs,  # BayesBay version 3.1 and above\n    #perturbation_funcs=parameterization.perturbation_functions, # BayesBay pre version 3.1 \n    log_like_ratio_func=log_likelihood,\n    n_chains=n_chains,\n    n_iterations=5_000,\n    burnin_iterations=500,\n    verbose=False,\n    save_every=25,\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv = cofi.Inversion(cofi.BaseProblem(), inv_options)\nmy_result = inv.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = my_result.models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\narviz.style.use(\"default\")\nvar_names = [\n    \"Dip (\\u00b0)\",\n    \"Dip Azimuth (\\u00b0)\",\n    \"Easting (m)\",\n    \"Depth (m)\",\n    \"Width (m)\",\n]\n\nresults = my_result.models\nposterior_samples = {\n    f\"{var_names[i]}\": numpy.concatenate(results[f\"param_space.m{i}\"])\n    for i in range(init_param_value.size)\n}\n\ntrue_values = {\n    f\"{var_names[i]}\": true_param_value[i] for i in range(init_param_value.size)\n}\n\n\nfig, axes = plt.subplots(5, 5, figsize=(10, 8))\n_ = arviz.plot_pair(\n    posterior_samples,\n    marginals=True,\n    kind=\"kde\",\n    kde_kwargs={\n        \"hdi_probs\": [0.3, 0.6, 0.9],  # Plot 30%, 60% and 90% HDI contours\n        \"contourf_kwargs\": {\"cmap\": \"Blues\"},\n    },\n    ax=axes,\n    textsize=10,\n)\n\nfor i, j in numpy.ndindex(axes.shape):\n    if i == j:\n        continue\n    xlabel = axes[-1, j].get_xlabel()\n    ylabel = axes[i, 0].get_ylabel()\n    x_true = true_values[xlabel]\n    y_true = true_values[ylabel]\n    axes[i, j].plot(x_true, y_true, \"yellow\", marker=\"o\", ms=10, markeredgecolor=\"k\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title plotting function (hidden)\n\n_, axes = plt.subplots(2, 2)\naxes[1, 1].axis(\"off\")\nplot_plate_faces(\n    \"plate_true\",\n    forward,\n    true_param_value,\n    axes[0, 0],\n    axes[0, 1],\n    axes[1, 0],\n    color=\"purple\",\n    label=\"True model\",\n)\nplot_plate_faces(\n    \"plate_init\",\n    forward,\n    init_param_value,\n    axes[0, 0],\n    axes[0, 1],\n    axes[1, 0],\n    color=\"green\",\n    label=\"Starting model\",\n)\n\nplt.tight_layout()\nidraw = numpy.random.randint(0, len(posterior_samples[var_names[0]]))\nsample = numpy.array([posterior_samples[name][idraw] for name in var_names])\n\nplot_plate_faces(\n    \"plate_inverted\",\n    forward,\n    sample,\n    axes[0, 0],\n    axes[0, 1],\n    axes[1, 0],\n    color=\"red\",\n    label=\"Posterior sample\",\n    linestyle=\"dotted\",\n)\n\npoint = Line2D(\n    [0],\n    [0],\n    label=\"Fiducial\",\n    marker=\"o\",\n    markersize=5,\n    markeredgecolor=\"orange\",\n    markerfacecolor=\"orange\",\n    linestyle=\"\",\n)\n\nhandles, labels = axes[1, 0].get_legend_handles_labels()\nhandles.extend([point])\n\naxes[1, 0].legend(handles=handles, bbox_to_anchor=(1.04, 0), loc=\"lower left\")\n\n# plot 10 randomly selected samples of the posterior distribution\nidraws = numpy.random.choice(\n    numpy.arange(0, len(posterior_samples[var_names[0]])), 10, replace=False\n)\nfor idraw in idraws:\n    sample = numpy.array([posterior_samples[name][idraw] for name in var_names])\n    plot_plate_faces(\n        \"plate_inverted\",\n        forward,\n        sample,\n        axes[0, 0],\n        axes[0, 1],\n        axes[1, 0],\n        color=\"red\",\n        label=\"Posterior sample\",\n        linestyle=\"dotted\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Where to next?\n\nThis tutorial is a based on the material available as a a CoFI example\nunder the following link\n\n<https://github.com/inlab-geo/cofi-examples/tree/main/examples/vtem_max>\n\nThe following two notebooks explore the inversion of a field data set\ncollected over the Caber deposit using the methods introduced in this\ntutorial.\n-[Preprocessing](https://github.com/inlab-geo/cofi-examples/blob/main/examples/vtem_max/caber_preprocessing.ipynb)\n-[Inversion](https://github.com/inlab-geo/cofi-examples/blob/main/examples/vtem_max/caber_inversion.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# Watermark\n\n<!-- Feel free to add more modules in the watermark_list below, if more packages are used -->\n<!-- Otherwise please leave the below code cell unchanged -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"numpy\", \"scipy\", \"matplotlib\",\"bayesbay\",\"smt\",\"neighpy\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}